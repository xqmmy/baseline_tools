{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bert4keras.backend import keras, set_gelu\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam, extend_with_piecewise_linear_lr\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "# from keras.layers import Lambda, Dense\n",
    "from keras.layers import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gelu('tanh')  # 切换gelu版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "maxlen = 128\n",
    "batch_size = 32\n",
    "config_path = '../model/albert_small_zh_google/albert_config_small_google.json'\n",
    "checkpoint_path = '../model/albert_small_zh_google/albert_model.ckpt'\n",
    "dict_path = '../model/albert_small_zh_google/vocab.txt'\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    model='albert',\n",
    "    return_keras_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义BiLSTM网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取bert的char embeeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_input = bert.layers['Embedding-Token'].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Bidirectional(LSTM(128, return_sequences=True))(lstm_input)\n",
    "lstm_output = Bidirectional(LSTM(128))(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类全联接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax'\n",
    ")(lstm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(bert.model.input[0], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input-Token (InputLayer)     (None, None)              0         \n",
      "_________________________________________________________________\n",
      "Embedding-Token (Embedding)  (None, None, 128)         2704384   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 256)         263168    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 3,362,306\n",
      "Trainable params: 3,362,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(1e-5),  \n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(valid_rate=0.3):\n",
    "    train_file = \"../data/train.csv\"\n",
    "    test_file = \"../data/test.csv\"\n",
    "    \n",
    "    df_train_data = pd.read_csv(\"../data/train.csv\").\\\n",
    "    drop_duplicates(['level_1', 'level_2', 'level_3', 'level_4', 'content', 'label'])\n",
    "    df_test_data = pd.read_csv(\"../data/test.csv\")\n",
    "    \n",
    "    train_data, valid_data, test_data = [], [], []\n",
    "    \n",
    "    for row_i, data in df_train_data.iterrows():\n",
    "        id, level_1, level_2, level_3, level_4, content, label = data\n",
    "        \n",
    "        id, text, label = id, str(level_1) + '\\t' + str(level_2) + '\\t' + \\\n",
    "        str(level_3) + '\\t' + str(level_4) + '\\t' + str(content), label\n",
    "        if random.random() > valid_rate:\n",
    "            train_data.append( (id, text, int(label)) )\n",
    "        else:\n",
    "            valid_data.append( (id, text, int(label)) )\n",
    "            \n",
    "    for row_i, data in df_test_data.iterrows():\n",
    "        id, level_1, level_2, level_3, level_4, content = data\n",
    "        \n",
    "        id, text, label = id, str(level_1) + '\\t' + str(level_2) + '\\t' + \\\n",
    "        str(level_3) + '\\t' + str(level_4) + '\\t' + str(content), 0\n",
    "        test_data.append( (id, text, int(label)) )\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = load_data(valid_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迭代器生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_labels = [], []\n",
    "        for is_end, (id, text, label) in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_labels.append([label])\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids], batch_labels\n",
    "                batch_token_ids, batch_labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练、验证和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(valid_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('best_model.weights')\n",
    "        test_acc = evaluate(valid_generator)\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f, test_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc, test_acc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pred(test_data):\n",
    "    id_ids, y_pred_ids = [], []\n",
    "    for id, text, label in test_data:\n",
    "        token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "        token_ids = sequence_padding([token_ids])\n",
    "        y_pred = int(model.predict([token_ids]).argmax(axis=1)[0])\n",
    "        id_ids.append(id)\n",
    "        y_pred_ids.append(y_pred)\n",
    "    return id_ids, y_pred_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "234/234 [==============================] - 171s 730ms/step - loss: 0.5201 - accuracy: 0.9257\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 2/10\n",
      "234/234 [==============================] - 171s 731ms/step - loss: 0.2515 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 3/10\n",
      "234/234 [==============================] - 167s 713ms/step - loss: 0.2434 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 4/10\n",
      "234/234 [==============================] - 168s 717ms/step - loss: 0.2384 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 5/10\n",
      "234/234 [==============================] - 170s 726ms/step - loss: 0.2329 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 6/10\n",
      "234/234 [==============================] - 170s 728ms/step - loss: 0.2270 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 7/10\n",
      "234/234 [==============================] - 168s 719ms/step - loss: 0.2218 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 8/10\n",
      "234/234 [==============================] - 167s 713ms/step - loss: 0.2160 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 9/10\n",
      "234/234 [==============================] - 174s 745ms/step - loss: 0.2090 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n",
      "Epoch 10/10\n",
      "234/234 [==============================] - 170s 728ms/step - loss: 0.1992 - accuracy: 0.9306\n",
      "val_acc: 0.92192, best_val_acc: 0.92192, test_acc: 0.92192\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb2406f82e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_generator.forfit(),\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=10,\n",
    "        callbacks=[evaluator]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看模型训练和验证结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test acc: 0.932546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u'final test acc: %05f\\n' % (evaluate(valid_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test acc: 0.926101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u'final test acc: %05f\\n' % (evaluate(train_generator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ids, y_pred_ids = data_pred(test_data)\n",
    "df_save = pd.DataFrame()\n",
    "df_save['id'] = id_ids\n",
    "df_save['label'] = y_pred_ids\n",
    "\n",
    "df_save.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs",
   "language": "python",
   "name": "bs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
