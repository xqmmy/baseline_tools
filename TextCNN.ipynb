{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bert4keras.backend import keras, set_gelu\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.optimizers import Adam, extend_with_piecewise_linear_lr\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "# from keras.layers import Lambda, Dense\n",
    "from keras.layers import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_gelu('tanh')  # 切换gelu版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "maxlen = 128\n",
    "batch_size = 32\n",
    "config_path = '../model/albert_small_zh_google/albert_config_small_google.json'\n",
    "checkpoint_path = '../model/albert_small_zh_google/albert_model.ckpt'\n",
    "dict_path = '../model/albert_small_zh_google/vocab.txt'\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "bert = build_transformer_model(\n",
    "    config_path=config_path,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    model='albert',\n",
    "    return_keras_model=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义TextCNN网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_dims = Lambda(lambda X:tf.expand_dims(X,axis=-1))\n",
    "max_pool = Lambda(lambda X:tf.squeeze(tf.reduce_max(X,axis=1),axis=1))\n",
    "concat = Lambda(lambda X: tf.concat(X, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取bert的char embeeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input = expand_dims(bert.layers['Embedding-Token'].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义cnn网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 2\n",
    "sizes = [3,5,7,9]\n",
    "output = []\n",
    "for size_i in sizes:\n",
    "    X = Conv2D(filters=2,\n",
    "                   kernel_size=(size_i, 128),\n",
    "                   activation='relu',\n",
    "                   )(cnn_input)\n",
    "    # X = tf.squeeze(tf.reduce_max(X,axis=1),axis=1)\n",
    "    X = max_pool(X)\n",
    "    output.append(X)\n",
    "# cnn_output = tf.concat(output, axis=-1)\n",
    "cnn_output = concat(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类全联接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(\n",
    "    units=num_classes,\n",
    "    activation='softmax'\n",
    ")(cnn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(bert.model.input[0], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 128, 1) 0           Embedding-Token[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, 1, 2)   770         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, 1, 2)   1282        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, 1, 2)   1794        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, 1, 2)   2306        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 8)            0           lambda_2[0][0]                   \n",
      "                                                                 lambda_2[1][0]                   \n",
      "                                                                 lambda_2[2][0]                   \n",
      "                                                                 lambda_2[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            18          lambda_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,710,554\n",
      "Trainable params: 2,710,554\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(1e-5),  \n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(valid_rate=0.3):\n",
    "    train_file = \"../data/train.csv\"\n",
    "    test_file = \"../data/test.csv\"\n",
    "    \n",
    "    df_train_data = pd.read_csv(\"../data/train.csv\").\\\n",
    "    drop_duplicates(['level_1', 'level_2', 'level_3', 'level_4', 'content', 'label'])\n",
    "    df_test_data = pd.read_csv(\"../data/test.csv\")\n",
    "    \n",
    "    train_data, valid_data, test_data = [], [], []\n",
    "    \n",
    "    for row_i, data in df_train_data.iterrows():\n",
    "        id, level_1, level_2, level_3, level_4, content, label = data\n",
    "        \n",
    "        id, text, label = id, str(level_1) + '\\t' + str(level_2) + '\\t' + \\\n",
    "        str(level_3) + '\\t' + str(level_4) + '\\t' + str(content), label\n",
    "        if random.random() > valid_rate:\n",
    "            train_data.append( (id, text, int(label)) )\n",
    "        else:\n",
    "            valid_data.append( (id, text, int(label)) )\n",
    "            \n",
    "    for row_i, data in df_test_data.iterrows():\n",
    "        id, level_1, level_2, level_3, level_4, content = data\n",
    "        \n",
    "        id, text, label = id, str(level_1) + '\\t' + str(level_2) + '\\t' + \\\n",
    "        str(level_3) + '\\t' + str(level_4) + '\\t' + str(content), 0\n",
    "        test_data.append( (id, text, int(label)) )\n",
    "    return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = load_data(valid_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迭代器生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_labels = [], []\n",
    "        for is_end, (id, text, label) in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_labels.append([label])\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_labels = sequence_padding(batch_labels)\n",
    "                yield [batch_token_ids], batch_labels\n",
    "                batch_token_ids, batch_labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)\n",
    "valid_generator = data_generator(valid_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练、验证和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    total, right = 0., 0.\n",
    "    for x_true, y_true in data:\n",
    "        y_pred = model.predict(x_true).argmax(axis=1)\n",
    "        y_true = y_true[:, 0]\n",
    "        total += len(y_true)\n",
    "        right += (y_true == y_pred).sum()\n",
    "    return right / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.best_val_acc = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = evaluate(valid_generator)\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = val_acc\n",
    "            model.save_weights('best_model.weights')\n",
    "        test_acc = evaluate(valid_generator)\n",
    "        print(\n",
    "            u'val_acc: %.5f, best_val_acc: %.5f, test_acc: %.5f\\n' %\n",
    "            (val_acc, self.best_val_acc, test_acc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pred(test_data):\n",
    "    id_ids, y_pred_ids = [], []\n",
    "    for id, text, label in test_data:\n",
    "        token_ids, segment_ids = tokenizer.encode(text, maxlen=maxlen)\n",
    "        token_ids = sequence_padding([token_ids])\n",
    "        y_pred = int(model.predict([token_ids]).argmax(axis=1)[0])\n",
    "        id_ids.append(id)\n",
    "        y_pred_ids.append(y_pred)\n",
    "    return id_ids, y_pred_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "234/234 [==============================] - 3s 13ms/step - loss: 0.3866 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 2/10\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.3233 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 3/10\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.2938 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 4/10\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.2795 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 5/10\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.2727 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 6/10\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.2689 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 7/10\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.2678 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 8/10\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.2661 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 9/10\n",
      "234/234 [==============================] - 3s 12ms/step - loss: 0.2659 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n",
      "Epoch 10/10\n",
      "234/234 [==============================] - 3s 11ms/step - loss: 0.2658 - accuracy: 0.9233\n",
      "val_acc: 0.93929, best_val_acc: 0.93929, test_acc: 0.93929\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8b006be1f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_generator.forfit(),\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=10,\n",
    "        callbacks=[evaluator]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看模型训练和验证结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model.weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test acc: 0.939288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u'final test acc: %05f\\n' % (evaluate(valid_generator)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final test acc: 0.923324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u'final test acc: %05f\\n' % (evaluate(train_generator)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ids, y_pred_ids = data_pred(test_data)\n",
    "df_save = pd.DataFrame()\n",
    "df_save['id'] = id_ids\n",
    "df_save['label'] = y_pred_ids\n",
    "\n",
    "df_save.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs",
   "language": "python",
   "name": "bs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
